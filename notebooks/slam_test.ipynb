{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loop closure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import plotly.graph_objects as go\n",
    "from copy import deepcopy\n",
    "\n",
    "import planeslam.io as io\n",
    "from planeslam.scan import pc_to_scan\n",
    "from planeslam.general import NED_to_ENU, trajectory_plot_trace\n",
    "from planeslam.geometry.util import quat_to_R\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load AirSim data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in point cloud data\n",
    "binpath = os.path.join(os.getcwd(), '..', 'data', 'airsim', 'blocks_60_samples_loop_closure', 'lidar', 'Drone0')\n",
    "PCs = io.read_lidar_bin(binpath)\n",
    "\n",
    "# Read in ground-truth poses (in drone local frame)\n",
    "posepath = os.path.join(os.getcwd(), '..', 'data', 'airsim', 'blocks_60_samples_loop_closure', 'poses', 'Drone0')\n",
    "drone_positions, drone_orientations = io.read_poses(posepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample data\n",
    "sub_factor = 5\n",
    "PCs = PCs[::sub_factor]\n",
    "drone_positions = drone_positions[::sub_factor]\n",
    "drone_orientations = drone_orientations[::sub_factor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to ENU\n",
    "num_scans = len(PCs)\n",
    "\n",
    "for i in range(num_scans):\n",
    "    PCs[i] = NED_to_ENU(PCs[i])\n",
    "\n",
    "drone_positions = NED_to_ENU(drone_positions)\n",
    "drone_orientations = NED_to_ENU(drone_orientations)\n",
    "\n",
    "drone_rotations = np.zeros((3,3,num_scans))\n",
    "for i in range(num_scans):\n",
    "    drone_rotations[:,:,i] = quat_to_R(drone_orientations[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ground-truth trajectory\n",
    "gt_traj_trace = go.Scatter3d(x=drone_positions[:,0], y=drone_positions[:,1], z=drone_positions[:,2], \n",
    "    marker=dict(size=5), hovertext=np.arange(len(drone_positions)))\n",
    "fig = go.Figure(data=gt_traj_trace)\n",
    "fig.update_layout(width=1000, height=600, scene=dict(aspectmode='data'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With PoseGraph class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from planeslam.pose_graph import PoseGraph\n",
    "from planeslam.registration import robust_GN_register, loop_closure_register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOP_CLOSURE_SEARCH_RADIUS = 10  # [m]\n",
    "LOOP_CLOSURE_PREV_THRESH = 5  # don't search for loop closures over this number of the previous scans\n",
    "init_pose = (quat_to_R(drone_orientations[0]), drone_positions[0,:].copy())\n",
    "\n",
    "#--------------------------------------------------------------#\n",
    "N = len(PCs)\n",
    "\n",
    "# Relative transformations\n",
    "R_hats = []\n",
    "t_hats = []\n",
    "\n",
    "# Absolute poses\n",
    "R_abs, t_abs = init_pose\n",
    "poses = N * [None]\n",
    "poses[0] = (R_abs, t_abs)\n",
    "positions = t_abs\n",
    "\n",
    "# Scans\n",
    "scans = N * [None]\n",
    "scans[0] = pc_to_scan(PCs[0])\n",
    "\n",
    "# Initalize pose graph\n",
    "g = PoseGraph()\n",
    "g.add_vertex(0, poses[0])\n",
    "\n",
    "avg_runtime = 0\n",
    "\n",
    "for i in range(1, N):\n",
    "    start_time = time.time()\n",
    "    P = PCs[i]\n",
    "    \n",
    "    # Extract scan\n",
    "    scans[i] = pc_to_scan(P)\n",
    "    scans[i].remove_small_planes(area_thresh=5.0)\n",
    "\n",
    "    # Registration\n",
    "    R_hat, t_hat = robust_GN_register(scans[i], scans[i-1])\n",
    "    t_abs += (R_abs @ t_hat).flatten()\n",
    "    R_abs = R_hat @ R_abs\n",
    "\n",
    "    # Save data\n",
    "    R_hats.append(R_hat)\n",
    "    t_hats.append(t_hat)\n",
    "    positions = np.vstack((positions, t_abs))\n",
    "    poses[i] = (R_abs.copy(), t_abs.copy())\n",
    "\n",
    "    # Pose graph update\n",
    "    g.add_vertex(i, poses[i])\n",
    "    g.add_edge([i-1, i], (R_hat, t_hat))\n",
    "\n",
    "    # Loop closure detection\n",
    "    if i > LOOP_CLOSURE_PREV_THRESH:\n",
    "        LC_dists = np.linalg.norm(t_abs - positions[:i-LOOP_CLOSURE_PREV_THRESH], axis=1)\n",
    "        LCs = np.argwhere(LC_dists < LOOP_CLOSURE_SEARCH_RADIUS)\n",
    "        if len(LCs) > 0:\n",
    "            # Find the lowest distance loop closure\n",
    "            j = LCs[np.argsort(LC_dists[LCs].flatten())[0]][0]\n",
    "            print(f'adding loop closure: ({i}, {j})')\n",
    "            R_LC, t_LC = loop_closure_register(scans[i], scans[j], poses[i], poses[j], t_loss_thresh=0.1)\n",
    "            # Add LC edge\n",
    "            g.add_edge([j, i], (R_LC, t_LC))\n",
    "            # Optimize graph\n",
    "            g.optimize()    \n",
    "\n",
    "    avg_runtime += time.time() - start_time\n",
    "\n",
    "avg_runtime /= N-1\n",
    "print(\"Done. Avg runtime: \", avg_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = g.get_positions()\n",
    "\n",
    "gt_traj_trace = go.Scatter3d(x=drone_positions[:,0], y=drone_positions[:,1], z=drone_positions[:,2], \n",
    "    marker=dict(size=5), hovertext=np.arange(len(drone_positions)), name=\"Ground-truth\")\n",
    "est_traj_trace = go.Scatter3d(x=positions[:,0], y=positions[:,1], z=positions[:,2], \n",
    "    marker=dict(size=5), hovertext=np.arange(len(positions)), name=\"Estimated\")\n",
    "fig = go.Figure(data=[gt_traj_trace, est_traj_trace])\n",
    "fig.update_layout(width=1500, height=900, scene=dict(aspectmode='data'), legend=dict(yanchor=\"top\", y=0.99, xanchor=\"right\", x=0.99))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With map generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from planeslam.pose_graph import PoseGraph\n",
    "from planeslam.registration import robust_GN_register, loop_closure_register\n",
    "from planeslam.slam import generate_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOP_CLOSURE_SEARCH_RADIUS = 10  # [m]\n",
    "LOOP_CLOSURE_PREV_THRESH = 5  # don't search for loop closures over this number of the previous scans\n",
    "init_pose = (quat_to_R(drone_orientations[0]), drone_positions[0,:].copy())\n",
    "\n",
    "#--------------------------------------------------------------#\n",
    "N = len(PCs)\n",
    "\n",
    "# Relative transformations\n",
    "R_hats = []\n",
    "t_hats = []\n",
    "\n",
    "# Absolute poses\n",
    "R_abs, t_abs = init_pose\n",
    "poses = [(R_abs, t_abs)]\n",
    "positions = t_abs\n",
    "\n",
    "# Scans\n",
    "scans = [pc_to_scan(PCs[0])]\n",
    "scans_transformed = [deepcopy(scans[0])]\n",
    "scans_transformed[0].transform(R_abs, t_abs)\n",
    "\n",
    "# Initalize pose graph\n",
    "g = PoseGraph()\n",
    "g.add_vertex(0, poses[0])\n",
    "\n",
    "# Initialize map\n",
    "map = scans[0]\n",
    "\n",
    "#avg_runtime = 0\n",
    "extraction_times = []\n",
    "registration_times = []\n",
    "loop_closure_times = []\n",
    "merging_times = []\n",
    "\n",
    "for i in range(1, N):\n",
    "    print(i)\n",
    "    #start_time = time.time()\n",
    "    P = PCs[i]\n",
    "    \n",
    "    # Extract scan\n",
    "    start_time = time.time()\n",
    "    scans.append(pc_to_scan(P))\n",
    "    scans[i].remove_small_planes(area_thresh=5.0)\n",
    "    extraction_times.append(time.time() - start_time)\n",
    "    \n",
    "    # Registration\n",
    "    start_time = time.time()\n",
    "    R_hat, t_hat = robust_GN_register(scans[i], scans[i-1])\n",
    "    registration_times.append(time.time() - start_time)\n",
    "    t_abs += (R_abs @ t_hat).flatten()\n",
    "    R_abs = R_hat @ R_abs\n",
    "\n",
    "    # Transform scan\n",
    "    # scans_transformed.append(deepcopy(scans[i]))\n",
    "    # scans_transformed[i].transform(R_abs, t_abs)\n",
    "    scan_transformed = deepcopy(scans[i])\n",
    "    scan_transformed.transform(R_abs, t_abs)\n",
    "\n",
    "    # Save data\n",
    "    R_hats.append(R_hat)\n",
    "    t_hats.append(t_hat)\n",
    "    positions = np.vstack((positions, t_abs))\n",
    "    poses.append((R_abs.copy(), t_abs.copy()))\n",
    "\n",
    "    # Pose graph update\n",
    "    g.add_vertex(i, poses[i])\n",
    "    g.add_edge([i-1, i], (R_hat, t_hat))\n",
    "\n",
    "    # Loop closure detection\n",
    "    start_time = time.time()\n",
    "    LC = False\n",
    "    if i > LOOP_CLOSURE_PREV_THRESH:\n",
    "        LC_dists = np.linalg.norm(t_abs - positions[:i-LOOP_CLOSURE_PREV_THRESH], axis=1)\n",
    "        LCs = np.argwhere(LC_dists < LOOP_CLOSURE_SEARCH_RADIUS)\n",
    "        if len(LCs) > 0:\n",
    "            # Find the lowest distance loop closure\n",
    "            j = LCs[np.argsort(LC_dists[LCs].flatten())[0]][0]\n",
    "            #print(f'adding loop closure: ({i}, {j})')\n",
    "            R_LC, t_LC = loop_closure_register(scans[i], scans[j], poses[i], poses[j], t_loss_thresh=0.1)\n",
    "            # Add LC edge\n",
    "            g.add_edge([j, i], (R_LC, t_LC))\n",
    "            # Optimize graph\n",
    "            g.optimize()    \n",
    "            # TODO: Re-create map\n",
    "            map = generate_map(g.get_poses(), scans)\n",
    "            LC = True\n",
    "    loop_closure_times.append(time.time() - start_time)\n",
    "\n",
    "    # Map update (merging)\n",
    "    start_time = time.time()\n",
    "    if not LC:\n",
    "        map = map.merge(scan_transformed, dist_thresh=7.5)\n",
    "        map.reduce_inside(p2p_dist_thresh=5)\n",
    "        map.fuse_edges(vertex_merge_thresh=2.0)\n",
    "    merging_times.append(time.time() - start_time)\n",
    "\n",
    "    # Visualization\n",
    "    fig = go.Figure(data=map.plot_trace(colors=['blue'], showlegend=False))\n",
    "    fig.update_layout(scene=dict(aspectmode='data', \n",
    "        xaxis=dict(visible=False), yaxis=dict(visible=False), zaxis=dict(visible=False)))\n",
    "    fig.write_image(\"images/map/map\"+str(i)+\".png\", width=600, height=480)\n",
    "\n",
    "    #avg_runtime += time.time() - start_time\n",
    "\n",
    "#avg_runtime /= N-1\n",
    "#print(\"Done. Avg runtime: \", avg_runtime)\n",
    "\n",
    "print(f\"Averages: \\n \\\n",
    "        extraction: {np.mean(extraction_times)} \\n \\\n",
    "        registration: {np.mean(registration_times)} \\n \\\n",
    "        loop closure: {np.mean(loop_closure_times)} \\n \\\n",
    "        merging: {np.mean(merging_times)} \\n \\\n",
    "        total: {np.mean(extraction_times) + np.mean(registration_times) + np.mean(loop_closure_times) + np.mean(merging_times)}\")\n",
    "\n",
    "print(f\"STD: \\n \\\n",
    "        extraction: {np.std(extraction_times)} \\n \\\n",
    "        registration: {np.std(registration_times)} \\n \\\n",
    "        loop closure: {np.std(loop_closure_times)} \\n \\\n",
    "        merging: {np.std(merging_times)} \\n \\\n",
    "        total: {np.sqrt(np.mean([np.var(extraction_times), np.var(registration_times), np.var(loop_closure_times), np.var(merging_times)]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean([np.var(extraction_times), np.var(registration_times), np.var(loop_closure_times), np.var(merging_times)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_extraction_time+avg_registration_time+avg_loop_closure_time+avg_merging_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = g.get_positions()\n",
    "\n",
    "gt_traj_trace = go.Scatter3d(x=drone_positions[:,0], y=drone_positions[:,1], z=drone_positions[:,2], \n",
    "    marker=dict(size=5), hovertext=np.arange(len(drone_positions)), name=\"Ground-truth\")\n",
    "est_traj_trace = go.Scatter3d(x=positions[:,0], y=positions[:,1], z=positions[:,2], \n",
    "    marker=dict(size=5), hovertext=np.arange(len(positions)), name=\"Estimated\")\n",
    "fig = go.Figure(data=[gt_traj_trace, est_traj_trace])\n",
    "fig.update_layout(width=1500, height=900, scene=dict(aspectmode='data'), legend=dict(yanchor=\"top\", y=0.99, xanchor=\"right\", x=0.99))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=map.plot_trace(colors=['blue']))\n",
    "fig.update_layout(width=1500, height=900, scene=dict(aspectmode='data'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from planeslam.scan import velo_pc_to_scan\n",
    "from planeslam.point_cloud import velo_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in point cloud data\n",
    "pcpath = os.path.join(os.getcwd(), '..', 'data', 'velodyne', '9_19_2022', 'flightroom', 'run_3', 'pcs')\n",
    "PCs = []\n",
    "select_idxs = np.arange(0, len(os.listdir(pcpath)), 5)\n",
    "for i in select_idxs:  \n",
    "    filename = os.path.join(pcpath, 'pc_'+str(i)+'.npy')\n",
    "    PC = np.load(filename)\n",
    "    PCs.append(PC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in pose data\n",
    "posepath = os.path.join(os.getcwd(), '..', 'data', 'velodyne', '9_19_2022', 'flightroom', 'run_3', 'poses')\n",
    "gt_poses = []\n",
    "for i in select_idxs:  \n",
    "    filename = os.path.join(posepath, 'pose_'+str(i)+'.npy')\n",
    "    pose = np.load(filename)\n",
    "    gt_poses.append(pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rover_rotations = np.zeros((3,3,len(gt_poses)))\n",
    "for i in range(len(gt_poses)):\n",
    "    rover_rotations[:,:,i] = quat_to_R(gt_poses[i][3:])\n",
    "\n",
    "# Transform ground truth to account for LiDAR offset\n",
    "offset_vec = np.array([0.09, 0.0, 0.0])\n",
    "shifted_poses = deepcopy(gt_poses)\n",
    "\n",
    "for i in range(len(PCs)):\n",
    "    # Rotate offset by current pose\n",
    "    shifted_poses[i][:3] += rover_rotations[:,:,i] @ offset_vec\n",
    "\n",
    "rover_positions = np.asarray(gt_poses)[:,:3]\n",
    "rover_positions_shifted = np.asarray(shifted_poses)[:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOP_CLOSURE_SEARCH_RADIUS = 0.2  # [m]\n",
    "LOOP_CLOSURE_PREV_THRESH = 50  # don't search for loop closures over this number of the previous scans\n",
    "init_pose = (rover_rotations[:,:,0], rover_positions_shifted[0,:].copy())\n",
    "\n",
    "#--------------------------------------------------------------#\n",
    "N = len(PCs)\n",
    "\n",
    "# Relative transformations\n",
    "R_hats = []\n",
    "t_hats = []\n",
    "\n",
    "# Absolute poses\n",
    "R_abs, t_abs = init_pose\n",
    "poses = [(R_abs, t_abs)]\n",
    "positions = t_abs\n",
    "\n",
    "# Scans\n",
    "scans = [velo_pc_to_scan(velo_preprocess(PCs[0], shifted_poses[0]))]\n",
    "scans_transformed = [deepcopy(scans[0])]\n",
    "scans_transformed[0].transform(R_abs, t_abs)\n",
    "\n",
    "# Initalize pose graph\n",
    "g = PoseGraph()\n",
    "g.add_vertex(0, poses[0])\n",
    "\n",
    "# Initialize map\n",
    "map = scans[0]\n",
    "\n",
    "#avg_runtime = 0\n",
    "extraction_times = []\n",
    "registration_times = []\n",
    "loop_closure_times = []\n",
    "merging_times = []\n",
    "\n",
    "for i in range(1, N):\n",
    "    print(i)\n",
    "    #start_time = time.time()\n",
    "    P = velo_preprocess(PCs[i], shifted_poses[i])\n",
    "    \n",
    "    # Extract scan\n",
    "    start_time = time.time()\n",
    "    scans.append(velo_pc_to_scan(P))\n",
    "    scans[i].remove_small_planes(area_thresh=0.1)\n",
    "    scans[i].reduce_inside(p2p_dist_thresh=0.1)\n",
    "    extraction_times.append(time.time() - start_time)\n",
    "    \n",
    "    # Registration\n",
    "    start_time = time.time()\n",
    "    R_hat, t_hat = robust_GN_register(scans[i], scans[i-1], c2c_thresh=1.0)\n",
    "    registration_times.append(time.time() - start_time)\n",
    "    t_abs += (R_abs @ t_hat).flatten()\n",
    "    R_abs = R_hat @ R_abs\n",
    "\n",
    "    # Transform scan\n",
    "    scan_transformed = deepcopy(scans[i])\n",
    "    scan_transformed.transform(R_abs, t_abs)\n",
    "\n",
    "    # Save data\n",
    "    R_hats.append(R_hat)\n",
    "    t_hats.append(t_hat)\n",
    "    positions = np.vstack((positions, t_abs))\n",
    "    poses.append((R_abs.copy(), t_abs.copy()))\n",
    "\n",
    "    # Pose graph update\n",
    "    g.add_vertex(i, poses[i])\n",
    "    g.add_edge([i-1, i], (R_hat, t_hat))\n",
    "\n",
    "    # Loop closure detection\n",
    "    start_time = time.time()\n",
    "    LC = False\n",
    "    if i > LOOP_CLOSURE_PREV_THRESH:\n",
    "        LC_dists = np.linalg.norm(t_abs - positions[:i-LOOP_CLOSURE_PREV_THRESH], axis=1)\n",
    "        LCs = np.argwhere(LC_dists < LOOP_CLOSURE_SEARCH_RADIUS)\n",
    "        if len(LCs) > 0:\n",
    "            # Find the lowest distance loop closure\n",
    "            j = LCs[np.argsort(LC_dists[LCs].flatten())[0]][0]\n",
    "            print(f\"loop closure ({i}, {j})\")\n",
    "            #print(f'adding loop closure: ({i}, {j})')\n",
    "            R_LC, t_LC = loop_closure_register(scans[i], scans[j], poses[i], poses[j], t_loss_thresh=0.1)\n",
    "            # Add LC edge\n",
    "            g.add_edge([j, i], (R_LC, t_LC))\n",
    "            # Optimize graph\n",
    "            g.optimize()    \n",
    "            # Regenerate map\n",
    "            map = generate_map(g.get_poses(), scans, dist_thresh=0.1, p2p_thresh=0.1, area_thresh=0.1, fuse_thresh=0.1)\n",
    "            LC = True\n",
    "    loop_closure_times.append(time.time() - start_time)\n",
    "\n",
    "    # Map update (merging)\n",
    "    start_time = time.time()\n",
    "    if not LC:\n",
    "        map = map.merge(scan_transformed, dist_thresh=0.1)\n",
    "        map.reduce_inside(p2p_dist_thresh=0.1)\n",
    "        map.fuse_edges(vertex_merge_thresh=0.1)\n",
    "    merging_times.append(time.time() - start_time)\n",
    "\n",
    "    # Visualization\n",
    "    # fig = go.Figure(data=map.plot_trace(colors=['blue'], showlegend=False))\n",
    "    # fig.update_layout(scene=dict(aspectmode='data', \n",
    "    #     xaxis=dict(visible=False), yaxis=dict(visible=False), zaxis=dict(visible=False)))\n",
    "    # fig.write_image(\"images/map/map\"+str(i)+\".png\", width=600, height=480)\n",
    "\n",
    "    #avg_runtime += time.time() - start_time\n",
    "\n",
    "#avg_runtime /= N-1\n",
    "#print(\"Done. Avg runtime: \", avg_runtime)\n",
    "\n",
    "print(f\"Averages: \\n \\\n",
    "        extraction: {np.mean(extraction_times)} \\n \\\n",
    "        registration: {np.mean(registration_times)} \\n \\\n",
    "        loop closure: {np.mean(loop_closure_times)} \\n \\\n",
    "        merging: {np.mean(merging_times)} \\n \\\n",
    "        total: {np.mean(extraction_times) + np.mean(registration_times) + np.mean(loop_closure_times) + np.mean(merging_times)}\")\n",
    "\n",
    "print(f\"STD: \\n \\\n",
    "        extraction: {np.std(extraction_times)} \\n \\\n",
    "        registration: {np.std(registration_times)} \\n \\\n",
    "        loop closure: {np.std(loop_closure_times)} \\n \\\n",
    "        merging: {np.std(merging_times)} \\n \\\n",
    "        total: {np.sqrt(np.mean([np.var(extraction_times), np.var(registration_times), np.var(loop_closure_times), np.var(merging_times)]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = g.get_positions()\n",
    "\n",
    "gt_traj_trace = go.Scatter3d(x=rover_positions_shifted[:,0], y=rover_positions_shifted[:,1], z=rover_positions_shifted[:,2], \n",
    "    marker=dict(size=5), hovertext=np.arange(len(rover_positions_shifted)), name=\"Ground-truth\")\n",
    "est_traj_trace = go.Scatter3d(x=positions[:,0], y=positions[:,1], z=positions[:,2], \n",
    "    marker=dict(size=5), hovertext=np.arange(len(positions)), name=\"Estimated\")\n",
    "fig = go.Figure(data=[gt_traj_trace, est_traj_trace])\n",
    "fig.update_layout(width=1500, height=900, scene=dict(aspectmode='data'), legend=dict(yanchor=\"top\", y=0.99, xanchor=\"right\", x=0.99))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "from planeslam.registration import get_correspondences\n",
    "\n",
    "source = scans[0]\n",
    "target = scans[1]\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, specs=[[{'type': 'surface'}, {'type': 'surface'}]])\n",
    "\n",
    "for t in source.plot_trace(show_normals=False):\n",
    "    fig.add_trace(t, row=1, col=1)\n",
    "#fig.add_trace(pc_plot_trace(P_source), row=1, col=1)\n",
    "\n",
    "for t in target.plot_trace(show_normals=False):\n",
    "    fig.add_trace(t, row=1, col=2)\n",
    "#fig.add_trace(pc_plot_trace(P_target), row=1, col=2)\n",
    "\n",
    "fig.update_layout(width=1600, height=500, scene=dict(aspectmode='data'), scene2=dict(aspectmode='data'))\n",
    "fig.show()\n",
    "\n",
    "correspondences = get_correspondences(source, target, c2c_thresh=1.0)\n",
    "print(correspondences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=map.plot_trace(colors=['blue']))\n",
    "fig.update_layout(width=1500, height=900, scene=dict(aspectmode='data'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
